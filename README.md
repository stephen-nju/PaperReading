# Paper Reading
-----------------------------------------------------------

## Papers
------------------------------------------------------------
### Video Moment Localization
------------------------------------------------------------
>Video moment localization, also known as video moment retrieval(VMR) or natural language video localization (NLVL) or temporal sentence grounding in videos (TSGV), aiming to retrieve a temporal moment that semantically corresponds to a language query from an untrimmed video.
- A Survey on Video Moment Localization(**arXiv 2022**)[[paper](https://dl.acm.org/doi/10.1145/3556537)]
- Temporal Sentence Grounding in Videos: A Survey and Future Directions(**arXiv 2022**)[[paper](http://arxiv.org/abs/2201.08071)]

###  Generic Event Boundary Detection
------------------------------------------------------------
>Cognitive Science has known since last century that humans consistently segment videos into meaningful temporal chunks.This segmentation happens naturally, without pre-defined event categories and without being explicitly asked to do so.This task aims at localizing the moments where humans naturally perceive event boundaries.
- Generic Event Boundary Detection: A Benchmark for Event Segmentation (**ACM Computing Surveys**)  [[paper](https://arxiv.org/pdf/2101.10511.pdf)]
